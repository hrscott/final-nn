{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general libraries needed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the 137 positive Rap1 motif examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences read from data/rap1-lieb-positives.txt: 137\n"
     ]
    }
   ],
   "source": [
    "from nn import io\n",
    "\n",
    "# Read in the sequences from the file\n",
    "filename = 'data/rap1-lieb-positives.txt'\n",
    "pos_seqs = io.read_text_file(filename)\n",
    "\n",
    "# Print the number of sequences read\n",
    "print(f\"Number of sequences read from {filename}: {len(pos_seqs)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences read from data/yeast-upstream-1k-negative.fa: 56908\n"
     ]
    }
   ],
   "source": [
    "# Read in the sequences from the file\n",
    "filename = 'data/yeast-upstream-1k-negative.fa'\n",
    "neg_seqs = io.read_text_file(filename)\n",
    "\n",
    "# Print the number of sequences read\n",
    "print(f\"Number of sequences read from {filename}: {len(neg_seqs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import preprocess\n",
    "from typing import List\n",
    "\n",
    "# Sample negative sequences to match number of positive sequences\n",
    "sampled_neg_seqs, _ = preprocess.sample_seqs(neg_seqs, [False] * len(neg_seqs))\n",
    "\n",
    "# Randomly sample 17-base-long substrings from each negative sequence\n",
    "processed_neg_seqs = []\n",
    "for seq in sampled_neg_seqs:\n",
    "    start_idx = np.random.randint(0, len(seq) - 16)\n",
    "    processed_neg_seqs.append(seq[start_idx:start_idx+17])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 1]\n",
      " [1 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 1 0 0]\n",
      " [1 0 0 ... 0 1 0]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_balanced_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(encoded_seqs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Create a list of labels for the balanced dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m y \u001b[39m=\u001b[39m [\u001b[39mTrue\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(X_balanced_pos) \u001b[39m+\u001b[39m [\u001b[39mFalse\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(X_balanced_neg)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Convert y to a numpy array\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_balanced_pos' is not defined"
     ]
    }
   ],
   "source": [
    "# Read in positive sequences\n",
    "pos_seqs = io.read_text_file(\"data/rap1-lieb-positives.txt\")\n",
    "\n",
    "# Read in negative sequences\n",
    "neg_seqs = io.read_fasta_file(\"data/yeast-upstream-1k-negative.fa\")\n",
    "\n",
    "# Sample negative sequences to balance dataset\n",
    "neg_seqs, _ = preprocess.sample_seqs(neg_seqs, [False]*len(neg_seqs))\n",
    "seqs = pos_seqs + neg_seqs\n",
    "labels = [True]*len(pos_seqs) + [False]*len(neg_seqs)\n",
    "\n",
    "# One-hot encode sequences\n",
    "encoded_seqs = preprocess.one_hot_encode_seqs(seqs)\n",
    "print(encoded_seqs)\n",
    "\n",
    "# Create a list of labels for the balanced dataset\n",
    "y = [True] * len(X_balanced_pos) + [False] * len(X_balanced_neg)\n",
    "\n",
    "# Convert y to a numpy array\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_seqs(seqs: List[str], labels: List[bool]) -> Tuple[List[str], List[bool]]:\n",
    "    \"\"\"\n",
    "    This function should sample the given sequences to account for class imbalance. \n",
    "    Consider this a sampling scheme with replacement.\n",
    "    \n",
    "    Args:\n",
    "        seqs: List[str]\n",
    "            List of all sequences.\n",
    "        labels: List[bool]\n",
    "            List of positive/negative labels\n",
    "\n",
    "    Returns:\n",
    "        sampled_seqs: List[str]\n",
    "            List of sampled sequences which reflect a balanced class size\n",
    "        sampled_labels: List[bool]\n",
    "            List of labels for the sampled sequences\n",
    "    \"\"\"\n",
    "    pos_seqs = [seq for seq, label in zip(seqs, labels) if label]\n",
    "    neg_seqs = [seq for seq, label in zip(seqs, labels) if not label]\n",
    "    \n",
    "    # Calculate number of sequences to sample from each class\n",
    "    n_pos = len(pos_seqs)\n",
    "    n_neg = len(neg_seqs)\n",
    "    n_samples = min(n_pos, n_neg)\n",
    "    \n",
    "    # Sample sequences with replacement\n",
    "    pos_samples = np.random.choice(pos_seqs, n_samples, replace=True)\n",
    "    neg_samples = np.random.choice(neg_seqs, n_samples, replace=True)\n",
    "    \n",
    "    # Combine the sampled sequences and labels\n",
    "    sampled_seqs = list(pos_samples) + list(neg_samples)\n",
    "    sampled_labels = [True] * n_samples + [False] * n_samples\n",
    "    \n",
    "    # Shuffle the sequences and labels\n",
    "    shuffle_idx = np.random.permutation(len(sampled_seqs))\n",
    "    sampled_seqs = [sampled_seqs[i] for i in shuffle_idx]\n",
    "    sampled_labels = [sampled_labels[i] for i in shuffle_idx]\n",
    "    \n",
    "    return sampled_seqs, sampled_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (219, 68)\n",
      "X_val shape: (55, 68)\n",
      "y_train shape: (219,)\n",
      "y_val shape: (55,)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from numpy.typing import ArrayLike\n",
    "from nn import io\n",
    "from nn import preprocess\n",
    "from nn import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the maximum sequence length\n",
    "MAX_SEQ_LENGTH = 17\n",
    "\n",
    "# Define the data file paths\n",
    "POSITIVE_FILE = 'data/rap1-lieb-positives.txt'\n",
    "NEGATIVE_FILE = 'data/yeast-upstream-1k-negative.fa'\n",
    "\n",
    "# Define the train/test split ratio\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# Read in the positive examples\n",
    "pos_seqs = io.read_text_file(POSITIVE_FILE)\n",
    "\n",
    "# Read in the negative examples and preprocess them\n",
    "neg_seqs = io.read_fasta_file(NEGATIVE_FILE)\n",
    "neg_seqs = [seq[:MAX_SEQ_LENGTH] for seq in neg_seqs]\n",
    "\n",
    "# Balance the classes using the sample_seq function\n",
    "labels = [True] * len(pos_seqs) + [False] * len(neg_seqs)\n",
    "seqs = pos_seqs + neg_seqs\n",
    "seqs, labels = sample_seqs(seqs, labels)\n",
    "\n",
    "# One-hot encode the sequences\n",
    "X = preprocess.one_hot_encode_seqs(seqs)\n",
    "y = np.array(labels, dtype=int)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_idx = np.random.permutation(len(X))\n",
    "X = X[shuffle_idx]\n",
    "y = y[shuffle_idx]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_idx = int(len(X) * TRAIN_RATIO)\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Print the shape of the data\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (64,1) and (64,64) not aligned: 1 (dim 1) != 64 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X14sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m nn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mNeuralNetwork(nn_arch, lr, seed, batch_size, epochs, loss_function)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X14sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Train the neural network\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m train_loss, val_loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_val, y_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Plot training and validation loss by epoch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(train_loss, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Algos/final/final-nn/nn/nn.py:211\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    209\u001b[0m     y_mini_batch \u001b[39m=\u001b[39m y_mini_batch\u001b[39m.\u001b[39mT\n\u001b[1;32m    210\u001b[0m     y_hat, cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(X_mini_batch)\n\u001b[0;32m--> 211\u001b[0m     grad_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackprop(y_mini_batch, y_hat, cache)\n\u001b[1;32m    212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_params(grad_dict)\n\u001b[1;32m    214\u001b[0m y_hat_train, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(X_train\u001b[39m.\u001b[39mT)\n",
      "File \u001b[0;32m~/Desktop/Algos/final/final-nn/nn/nn.py:172\u001b[0m, in \u001b[0;36mNeuralNetwork.backprop\u001b[0;34m(self, y, y_hat, cache)\u001b[0m\n\u001b[1;32m    168\u001b[0m Z_curr \u001b[39m=\u001b[39m cache[\u001b[39m\"\u001b[39m\u001b[39mZ\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(layer_idx_curr)]\n\u001b[1;32m    170\u001b[0m W_curr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_param_dict[\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(layer_idx_curr)]\n\u001b[0;32m--> 172\u001b[0m dA_prev, dW_curr, db_curr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_single_backprop(\n\u001b[1;32m    173\u001b[0m     dA_curr, W_curr, Z_curr, A_prev, activation_curr\n\u001b[1;32m    174\u001b[0m )\n\u001b[1;32m    176\u001b[0m grad_dict[\u001b[39m\"\u001b[39m\u001b[39mdW\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(layer_idx_curr)] \u001b[39m=\u001b[39m dW_curr\n\u001b[1;32m    177\u001b[0m grad_dict[\u001b[39m\"\u001b[39m\u001b[39mdb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(layer_idx_curr)] \u001b[39m=\u001b[39m db_curr\n",
      "File \u001b[0;32m~/Desktop/Algos/final/final-nn/nn/nn.py:146\u001b[0m, in \u001b[0;36mNeuralNetwork._single_backprop\u001b[0;34m(self, dA_curr, W_curr, Z_curr, A_prev, activation_curr)\u001b[0m\n\u001b[1;32m    144\u001b[0m dW_curr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(dZ_curr, A_prev\u001b[39m.\u001b[39mT) \u001b[39m/\u001b[39m m\n\u001b[1;32m    145\u001b[0m db_curr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(dZ_curr, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m/\u001b[39m m\n\u001b[0;32m--> 146\u001b[0m dA_prev \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(W_curr\u001b[39m.\u001b[39;49mT, dZ_curr)\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m dA_prev, dW_curr, db_curr\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (64,1) and (64,64) not aligned: 1 (dim 1) != 64 (dim 0)"
     ]
    }
   ],
   "source": [
    "from nn import io\n",
    "from nn import preprocess\n",
    "from nn import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading in data\n",
    "positive_seqs = io.read_text_file(\"data/rap1-lieb-positives.txt\")\n",
    "negative_seqs_raw = io.read_fasta_file(\"data/yeast-upstream-1k-negative.fa\")\n",
    "\n",
    "# Process negative examples to the same length as positive examples:\n",
    "seq_length = len(positive_seqs[0])\n",
    "negative_seqs = [seq[i:i+seq_length] for seq in negative_seqs_raw for i in range(0, len(seq) - seq_length + 1)]\n",
    "\n",
    "# Balance classes using the sample_seqs function\n",
    "all_seqs, all_labels = preprocess.sample_seqs(positive_seqs + negative_seqs, [True] * len(positive_seqs) + [False] * len(negative_seqs))\n",
    "\n",
    "# Encode sequences\n",
    "encoded_seqs = preprocess.one_hot_encode_seqs(all_seqs)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_idx = int(0.8 * len(all_labels))\n",
    "X_train, y_train = encoded_seqs[:split_idx], np.array(all_labels[:split_idx]).reshape(-1, 1)\n",
    "X_val, y_val = encoded_seqs[split_idx:], np.array(all_labels[split_idx:]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "\n",
    "nn_arch = [    {\"input_dim\": 4 * seq_length, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "               {\"input_dim\": 64, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "               {\"input_dim\": 64, \"output_dim\": 1, \"activation\": \"sigmoid\"}]\n",
    "\n",
    "\n",
    "# nn_arch = [\n",
    "#     {\"input_dim\": 4 * seq_length, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "#     {\"input_dim\": 64, \"output_dim\": 32, \"activation\": \"relu\"},\n",
    "#     {\"input_dim\": 32, \"output_dim\": 1, \"activation\": \"sigmoid\"}\n",
    "# ]\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.01\n",
    "seed = 42\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "loss_function = \"binary_cross_entropy\"\n",
    "\n",
    "# Create NeuralNetwork instance\n",
    "nn = nn.NeuralNetwork(nn_arch, lr, seed, batch_size, epochs, loss_function)\n",
    "\n",
    "# Train the neural network\n",
    "train_loss, val_loss = nn.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Plot training and validation loss by epoch\n",
    "plt.plot(train_loss, label=\"Training Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Report the accuracy of the classifier on the validation dataset\n",
    "y_val_pred = (nn.predict(X_val) > 0.5).astype(int)\n",
    "accuracy = np.mean(y_val_pred == y_val)\n",
    "print(f\"Validation accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (274, 54)\n",
      "y_train shape: (54, 1)\n",
      "X_val shape: (274, 14)\n",
      "y_val shape: (220, 1)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X15sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39my_val shape:\u001b[39m\u001b[39m\"\u001b[39m, y_val\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X15sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Train the neural network\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X15sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m train_loss, val_loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_val, y_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Plot training and validation loss by epoch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryrscott/Desktop/Algos/final/final-nn/classifier.ipynb#X15sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(train_loss, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Algos/final/final-nn/nn/nn.py:205\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    202\u001b[0m val_loss_history \u001b[39m=\u001b[39m []\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[0;32m--> 205\u001b[0m     mini_batches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_mini_batches(X_train, y_train)\n\u001b[1;32m    207\u001b[0m     \u001b[39mfor\u001b[39;00m X_mini_batch, y_mini_batch \u001b[39min\u001b[39;00m mini_batches:\n\u001b[1;32m    208\u001b[0m         X_mini_batch \u001b[39m=\u001b[39m X_mini_batch\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/Desktop/Algos/final/final-nn/nn/nn.py:235\u001b[0m, in \u001b[0;36mNeuralNetwork._get_mini_batches\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_mini_batches\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    232\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m#    Generate mini-batches from the input data X and target data y.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m#     \"\"\"\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m     \u001b[39massert\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    236\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    237\u001b[0m     np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(indices)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nn import io, preprocess, nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read in the positive examples\n",
    "positive_seqs = io.read_text_file(\"data/rap1-lieb-positives.txt\")\n",
    "\n",
    "# Read in the negative examples and preprocess them to the same length as positive examples\n",
    "negative_seqs_raw = io.read_fasta_file(\"data/yeast-upstream-1k-negative.fa\")\n",
    "seq_length = len(positive_seqs[0])\n",
    "negative_seqs = [seq[i:i+seq_length] for seq in negative_seqs_raw for i in range(0, len(seq) - seq_length + 1)]\n",
    "\n",
    "# Balance classes using the sample_seqs function\n",
    "all_seqs, all_labels = preprocess.sample_seqs(positive_seqs + negative_seqs, [True] * len(positive_seqs) + [False] * len(negative_seqs))\n",
    "\n",
    "# One-hot encode sequences\n",
    "encoded_seqs = preprocess.one_hot_encode_seqs(all_seqs)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_idx = int(0.8 * encoded_seqs.shape[1])\n",
    "X_train, y_train = encoded_seqs[:, :split_idx], np.array(all_labels[:split_idx]).reshape(-1, 1)\n",
    "X_val, y_val = encoded_seqs[:, split_idx:], np.array(all_labels[split_idx:]).reshape(-1, 1)\n",
    "\n",
    "# Define the neural network architecture\n",
    "nn_arch = [\n",
    "    {\"input_dim\": 4 * seq_length, \"output_dim\": 64, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 64, \"output_dim\": 32, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 32, \"output_dim\": 1, \"activation\": \"sigmoid\"}\n",
    "]\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.01\n",
    "seed = 42\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "loss_function = \"binary_cross_entropy\"\n",
    "\n",
    "# Create NeuralNetwork instance\n",
    "nn = nn.NeuralNetwork(nn_arch, lr, seed, batch_size, epochs, loss_function)\n",
    "\n",
    "# Check the shapes of X_train and y_train\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Check the shapes of X_val and y_val\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "# Train the neural network\n",
    "train_loss, val_loss = nn.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Plot training and validation loss by epoch\n",
    "plt.plot(train_loss, label=\"Training Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Report the accuracy of the classifier on the validation dataset\n",
    "y_val_pred = (nn.predict(X_val) > 0.5).astype(int)\n",
    "accuracy = np.mean(y_val_pred == y_val)\n",
    "print(f\"Validation accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
